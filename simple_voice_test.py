#!/usr/bin/env python3
"""
Simple Voice Output Test
Demonstrates the exact voice output format: "One person detected on Slight Right zone at 50 cm"
"""

import cv2
import time
import numpy as np

def test_exact_voice_format():
    """Test the exact voice output format you requested"""
    
    print("ğŸ¯ Testing Exact Voice Output Format")
    print("=" * 50)
    
    # Your exact requested format
    examples = [
        "One person detected on Slight Right zone at 50 cm",
        "One person detected on Center zone at 45 cm", 
        "One person detected on Far Left zone at 67 cm",
        "Two people detected: one in Slight Left zone and one in Slight Right zone at 89 cm",
        "Car detected on Center zone at 123 cm",
        "Chair detected on Slight Right zone at 156 cm"
    ]
    
    for i, example in enumerate(examples, 1):
        print(f"{i}. ğŸ”Š VOICE: {example}")
        time.sleep(1)
    
    print("\nâœ… Voice format test completed!")

def test_real_time_detection():
    """Test real-time detection with exact voice format"""
    
    print("\nğŸ¬ Testing Real-Time Detection with Voice Output")
    print("=" * 50)
    
    # Load face detection
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    
    if face_cascade.empty():
        print("âŒ Face detection model failed to load")
        return
    
    print("âœ… Face detection model loaded")
    
    # Open camera
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ Could not open camera")
        return
    
    print("âœ… Camera opened successfully")
    print("ğŸ“· Move your face around to test voice output")
    print("   Press Ctrl+C to stop")
    
    # Constants for distance calculation
    KNOWN_DISTANCE = 50  # cm
    KNOWN_FACE_WIDTH = 15  # cm
    
    focal_length = None
    calibrated = False
    frame_count = 0
    last_announcement_time = 0
    announcement_interval = 3  # Announce every 3 seconds
    
    def create_voice_announcement(message):
        """Simulate voice announcement"""
        print(f"ğŸ”Š VOICE: {message}")
    
    def get_zone_name(center_x, frame_width):
        """Get zone name based on x position"""
        zone_width = frame_width // 5
        zone_idx = min(center_x // zone_width, 4)
        zone_names = ["Far Left", "Slight Left", "Center", "Slight Right", "Far Right"]
        return zone_names[zone_idx]
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                continue
            
            frame_count += 1
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(gray, 1.3, 5)
            
            # Auto-calibrate on first face detection
            if not calibrated and len(faces) > 0:
                largest_face = max(faces, key=lambda x: x[2] * x[3])
                x, y, w, h = largest_face
                focal_length = (w * KNOWN_DISTANCE) / KNOWN_FACE_WIDTH
                calibrated = True
                print(f"âœ… Auto-calibrated! Focal length: {focal_length:.2f}")
            
            # Process detections and create announcements
            if calibrated and focal_length and len(faces) > 0:
                # Calculate distance for closest face
                closest_face = min(faces, key=lambda x: x[2] * x[3])
                x, y, w, h = closest_face
                distance = (KNOWN_FACE_WIDTH * focal_length) / w
                
                # Get zone
                center_x = x + w // 2
                zone_name = get_zone_name(center_x, frame.shape[1])
                
                # Create exact format message
                if len(faces) == 1:
                    message = f"One person detected on {zone_name} zone at {distance:.0f} cm"
                else:
                    message = f"{len(faces)} people detected on {zone_name} zone at {distance:.0f} cm"
                
                # Announce every few seconds
                current_time = time.time()
                if current_time - last_announcement_time > announcement_interval:
                    create_voice_announcement(message)
                    last_announcement_time = current_time
                
                # Print status every 30 frames
                if frame_count % 30 == 0:
                    print(f"ğŸ“ {len(faces)} face(s) at {distance:.1f}cm in {zone_name} zone")
            
            # Print status every 60 frames
            if frame_count % 60 == 0:
                if calibrated:
                    print(f"ğŸ”„ Status: {len(faces)} face(s) detected, Focal length: {focal_length:.1f}")
                else:
                    print("ğŸ”„ Status: Waiting for face detection to calibrate...")
            
            # Brief pause
            time.sleep(0.033)  # ~30 FPS
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ Test stopped by user")
    except Exception as e:
        print(f"âŒ Error: {e}")
    finally:
        cap.release()
        print("âœ… Camera released")
        print(f"ğŸ“Š Test summary:")
        print(f"   - Frames processed: {frame_count}")
        print(f"   - Calibrated: {calibrated}")
        if calibrated:
            print(f"   - Focal length: {focal_length:.2f}")

if __name__ == "__main__":
    print("ğŸš€ Starting Simple Voice Output Test")
    print("=" * 50)
    
    # Test the exact format
    test_exact_voice_format()
    
    # Test real-time detection
    test_real_time_detection()
    
    print("\n" + "=" * 50)
    print("âœ… All tests completed!")
    print("\nğŸ¯ Your i-sight system provides voice output in the exact format:")
    print("   'One person detected on [Zone] zone at [Distance] cm'") 